{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambiente local de desenvolvimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste tutorial iremos prever a categoria de renda das pessoas com base no conjunto de dados de rendimento do Censo dos Estados Unidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração do Ambiente\n",
    "\n",
    "O primeiro passo é configurar o ambiente com todos os artefatos que iremos usar neste notebook, tais como as bibliotecas do Python, além os dados e diretórios de entrada e saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O workspace de desenvolvimento estará em census_workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workspace_path = 'census_scikit'\n",
    "!mkdir -p {workspace_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA**: Se você já tiver executado esse notebook, limpe o ambiente antes de continuar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf {workspace_path} && mkdir {workspace_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria a pasta onde serão armazenados os dados do Censo dos EUA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir {workspace_path}/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo realiza o download dos arquivos de entrada dos dados do Censo dos EUA e armazena localmente em {workspace_path}/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = os.path.join(workspace_path, 'data')\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "response = requests.get(url)\n",
    "name = os.path.basename(url)\n",
    "with open(os.path.join(path, name), 'w') as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O arquivo **adult.data** foi copiado para a pasta *data* e contém 32.562 linhas sem cabeçalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls {workspace_path}/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No código abaixo, os dados são lidos do arquivo csv e armazenados no Dataframe *original_data*. Como o arquivo csv não tinha cabeçalho, foi inserido um cabeçalho no momento da leitura do csv no método *pd.read_csv*. O cabeçalho foi construído olhando o arquivo [adult.names](http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names) e está armazenado no vetor \\_CSV\\_COLUMNS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_CSV_COLUMNS = [\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',\n",
    "    'education',\n",
    "    'education-num',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital-gain',\n",
    "    'capital-loss',\n",
    "    'hours-per-week',\n",
    "    'native-country',\n",
    "    'income',\n",
    "]\n",
    "\n",
    "data_path = os.path.join(workspace_path, 'data')\n",
    "original_data = pd.read_csv(os.path.join(data_path, 'adult.data'), names=_CSV_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados\n",
    "\n",
    "O pré-processamento é um passo importante na execução de algoritmos de Machine Learning, podendo mudar drásticamente a eficácia do algoritmo. No site do [scikit-learn](http://scikit-learn.org/stable/modules/preprocessing.html#) existem vários métodos e algoritmos para pré-processamento.\n",
    "\n",
    "Antes de realizar o pré-processamento, temos que visualizar uma amostra dos dados para verificar quais métodos utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "hiddenCell": true
   },
   "outputs": [],
   "source": [
    "original_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nas 5 linhas acima, podemos ver que temos alguns atributos categóricos, inclusive nosso **alvo**, o atributo **income**. Vamos transformar estes atributos categóricos em atributos numéricos contínuos para que os algoritmos do Scikit possam trabalhar de forma correta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tranforma os atributos categóricos em números\n",
    "encoded_data = original_data.apply(preprocessing.LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo plotamos a correlação entre os atributos de entrada. Nesta correlação podemos perceber quais atributos tem mais correlação com nosso atributo alvo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(encoded_data.corr(), square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos perceber no gráfico acima e na tabela abaixo que os atributos *education* e *education_num* possuem correlação muito alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_data[[\"education\", \"education-num\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pode ser visto acima, as duas colunas representam as mesmas características, mas codificadas como string e número. Não precisamos das duas e, por isso, podemos remover uma delas. Vamos manter *education-num* já que os seus valores são numéricos e ordenados, ou seja, quanto maior o valor de *education-num* maior é o nível educacional da pessoa. Essa informação pode ser importante para vários algoritmos de Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del encoded_data[\"education\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maior parte dos algoritmos de Machine Learning requer padronização do conjunto de dados. Eles podem se comportar de forma inesperada se algumas features não tiver distribuição normalizada dos dados. Por isso, padronizamos a entrada com o StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prepara os dados\n",
    "y_all = encoded_data['income']\n",
    "X_all = encoded_data.drop(['income'], axis=1)\n",
    "\n",
    "#Padroniza os dados\n",
    "X_all_std = preprocessing.StandardScaler().fit_transform(X_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construção do classificador\n",
    "\n",
    "Na construção do modelo, primeiro temos que separar a base de treino para não gerar overfitting, onde o modelo se ajusta muito bem ao conjunto de dados anteriormente observado, mas se mostra ineficaz para prever novos resultados, que é nosso objetivo nesse problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Separa os dados em conjunto de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all_std, y_all, train_size=0.70, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos a base de dados de treinamento e teste, podemos executar os algoritmos de classificação. Existem diversos algoritmos de aprendizado [supervisionado](http://scikit-learn.org/stable/supervised_learning.html) e [não supervisionado](http://scikit-learn.org/stable/unsupervised_learning.html) no site do **scikit-learn**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Regressão Logística](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "O primeiro modelo analisado é a regressão logística que permite prever valores em relação a uma variável categórica, frequentemente binária, a partir de uma série de variáveis explicativas contínuas e/ou binárias. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cls = linear_model.LogisticRegression()\n",
    "cls.fit(X_train, y_train)\n",
    "y_pred = cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para avaliar o nosso modelo, usamos a métrica F1. Quanto MAIOR o valor desta métrica, MELHOR é o modelo.**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"F1 score: %f\" % skl.metrics.f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado da classificação pode ser vista no gráfico de calor abaixo, onde é possível visualizar o número de casos onde o modelo indicou resultados diferentes do correto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,1,1)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.ylabel(\"Real value\")\n",
    "plt.xlabel(\"Predicted value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vimos que o F1 score não tem um valor alto. Para tentar melhorar o modelo, podemos primeiro visualizar quais atributos contribuiram de forma negativa e positiva para a predição.\n",
    "Como pode ser visto no gráfico abaixo, as features *education-num*, *capital-gain* e *age* tem impacto positivo no modelo, enquanto *marital-status* e *relationship* tem impacto negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coefs = pd.Series(cls.coef_[0], index=X_all.columns).sort_values()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,1,2)\n",
    "coefs.plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa abordagem prejudica o modelo já que estamos colocando uma ordem arbitrária em nossas classes. Por exemplo, codificamos *relationship* como um número entre 1 e 5 e o modelo de Regressão Logística interpreta esses valores como variáveis contínuas e os coloca em uma função de otimização. Com isto diferentes classes terão diferentes pesos em nosso modelo, o que não é correto. Cada classe tem, teoricamente, o mesmo peso das outras classes. Para resolver este problema, podemos binarizar as features, ou seja, gerar todas as classes de cada feature e colocar tudo como 0 e 1. Isso é denominado *Feature binarization*. Neste tutorial iremos utilizar *Florestas Aleatórias* ou *Random Forest* para resolver este problemas, já que estas conseguem trabalhar com variáveis categorizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "Na área de Machine Learning espera-se que a combinação dos resultados de vários classificadores apresente melhor desempenho e maior convicção a tomada de decisão do que apenas um classificador. O algoritmo Random Forest (RF) é um termo geral para métodos de ensemble utilizando classificadores do tipo árvore. A RF constrói uma grande quantidade de árvores de decisão para fora do sub-conjunto de dados a partir de um treinamento único definido. Tal treinamento é realizado usando *bagging*. A utilização de bagging no treinamento além de reduzir a variância ajuda a evitar o overfitting. Este procedimento extrai casos aleatoriamente a partir de conjuntos de dados de treinamento originais e os conjuntos são usados para construir cada uma das árvores de decisão que compõe a RF. A RF constrói sua decisão por meio da contagem dos votos dos componentes preditores em cada classe e, em seguida, seleciona a classe vencedora em termos de número de votos acumulados. Para rodar o Random Forest, basta executar o código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cls = RandomForestClassifier()\n",
    "cls.fit(X_train, y_train)\n",
    "y_pred = cls.predict(X_test)\n",
    "\n",
    "print \"F1 score: %f\" % skl.metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,1,1)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.ylabel(\"Real value\")\n",
    "plt.xlabel(\"Predicted value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver acima que o score aumentou consideravemente com o uso do Random Forest. Como pode ser visto, o uso do modelo de Machine Learning correto de acordo com os dados pode fazer toda a diferença! Neste caso com variáveis categóricas, o uso de árvores de decisão é melhor por lidar melhor com este tipo de variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
